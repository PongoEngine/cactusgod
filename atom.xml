<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Cactus God</title>
  <icon>https://cactusgod.com/icon.png</icon>
  
  <link href="https://cactusgod.com/atom.xml" rel="self"/>
  
  <link href="https://cactusgod.com/"/>
  <updated>2023-07-12T03:50:53.162Z</updated>
  <id>https://cactusgod.com/</id>
  
  <author>
    <name>Jeremy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Waves of Sensation</title>
    <link href="https://cactusgod.com/twtwelve/waves-of-sensation/"/>
    <id>https://cactusgod.com/twtwelve/waves-of-sensation/</id>
    <published>2023-07-14T00:00:00.000Z</published>
    <updated>2023-07-12T03:50:53.162Z</updated>
    
    
    <summary type="html">&lt;p&gt;In the domain of racing simulators, the pursuit of immersive experiences goes beyond the graphical representation of the racing environment. One crucial facet is haptic feedback, which enables players to ‘feel’ their virtual ride. This post will delve into how different waveforms – sawtooth, sine, and square – can convey detailed haptic information from multiple sources into a single feedback channel.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>The Science of Smash</title>
    <link href="https://cactusgod.com/twtwelve/science-of-smash/"/>
    <id>https://cactusgod.com/twtwelve/science-of-smash/</id>
    <published>2023-07-13T00:00:00.000Z</published>
    <updated>2023-07-12T03:50:53.162Z</updated>
    
    
    <summary type="html">&lt;p&gt;The adrenaline rush in a racing simulator is not just about mastering the art of maneuvering around bends at dizzying speeds; it’s also about the abruptness of a high-speed crash. But with limited telemetry data from the game often lacking specific collision information, how do we detect and quantify the severity of a crash?&lt;/p&gt;
&lt;p&gt;Thankfully the regular updates we get from the simulator — 60 times a second, to be precise — provides an opportunity. This high-frequency data, specifically the velocity data, can be our secret weapon in detecting and quantifying crash events.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Tuning Into the Symphony of Road Noise</title>
    <link href="https://cactusgod.com/twtwelve/tuning-road-noise/"/>
    <id>https://cactusgod.com/twtwelve/tuning-road-noise/</id>
    <published>2023-07-12T00:00:00.000Z</published>
    <updated>2023-07-12T03:50:53.162Z</updated>
    
    
    <summary type="html">&lt;p&gt;When it comes to immersive driving experiences in simulators, the devil is in the details. Even the road’s texture, from smoothly paved highways to bumpy off-road trails, should not only reflect visually but should also echo in the audio rendering. In this context, it might seem puzzling: how can we convert the jargon of suspension data into the language of sound?&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Decoding the AUDIO_UTIL_mix function</title>
    <link href="https://cactusgod.com/twtwelve/audio-util-mix/"/>
    <id>https://cactusgod.com/twtwelve/audio-util-mix/</id>
    <published>2023-07-11T00:00:00.000Z</published>
    <updated>2023-07-12T03:50:53.162Z</updated>
    
    
    <summary type="html">&lt;p&gt;Racing simulators hinge on immersive experiences, and achieving quality sound plays a significant role. The crux lies in accurately blending multiple audio signals without distortion or clipping - a consequence of exceeding the system’s maximum limit.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
