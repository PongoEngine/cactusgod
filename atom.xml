<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Cactus God</title>
  <icon>https://cactusgod.com/icon.png</icon>
  
  <link href="https://cactusgod.com/atom.xml" rel="self"/>
  
  <link href="https://cactusgod.com/"/>
  <updated>2023-07-12T02:34:50.443Z</updated>
  <id>https://cactusgod.com/</id>
  
  <author>
    <name>Jeremy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Tuning Into the Symphony of Road Noise</title>
    <link href="https://cactusgod.com/twtwelve/tuning-road-noise/"/>
    <id>https://cactusgod.com/twtwelve/tuning-road-noise/</id>
    <published>2023-07-12T00:00:00.000Z</published>
    <updated>2023-07-12T02:34:50.443Z</updated>
    
    
    <summary type="html">&lt;p&gt;When it comes to immersive driving experiences in simulators, the devil is in the details. Even the road’s texture, from smoothly paved highways to bumpy off-road trails, should not only reflect visually but should also echo in the audio rendering. In this context, it might seem puzzling: how can we convert the jargon of suspension data into the language of sound?&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Decoding the AUDIO_UTIL_mix function</title>
    <link href="https://cactusgod.com/twtwelve/audio-util-mix/"/>
    <id>https://cactusgod.com/twtwelve/audio-util-mix/</id>
    <published>2023-07-11T00:00:00.000Z</published>
    <updated>2023-07-12T02:34:50.443Z</updated>
    
    
    <summary type="html">&lt;p&gt;Racing simulators hinge on immersive experiences, and achieving quality sound plays a significant role. The crux lies in accurately blending multiple audio signals without distortion or clipping - a consequence of exceeding the system’s maximum limit.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
